{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87ffa17",
   "metadata": {},
   "source": [
    "Optimizing urban road traffic using AI - assignment\n",
    "\n",
    "Termin: 22 czerwca 2025 23:59\n",
    "Instrukcje\n",
    "Download the dataset from https://drive.google.com/file/d/1m5xgNXp3vv5zzH4JHfE9983cLiSR3IPp/view\n",
    "\n",
    "In the file, you have 105336 rows. In each row, the first 21 elements are offsets at 21 intersections in Warsaw (a part of the Ochota district), while the last element is the total waiting time at red lights for all cars during a simulation of 10 minutes of realistic traffic (it was calculated using the Traffic Simulation Framework tool). The offsets are times (in seconds) from the start of the simulation to the first transition (of a selected signal state at the given intersection) from the red signal state to the green signal state. The values of the offsets are integers from the set {0,1,2,...,119}. The total wait times at red signals are also integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27aabd",
   "metadata": {},
   "source": [
    "Your task is to implement a pipeline for:\n",
    "\n",
    "1) Reading the data.\n",
    "\n",
    "2) Splitting the dataset into a training set (first 85336 rows) and a test set (last 20000 rows).\n",
    "\n",
    "3) Preprocessing the data (e.g., you can normalize the inputs and outputs).\n",
    "\n",
    "4) Training at least 1 machine learning model (e.g., a feed-forward neural network, XGBoost, or LightGBM) to predict the total wait time at red signals based on the 21 offsets.\n",
    "\n",
    "5) Calculating the MAPE (Mean Absolute Percentage Error) of the trained model(s) on the test set and presenting the results.\n",
    "\n",
    "6) Optimizing the hyperparameters of your model, if needed.\n",
    "\n",
    "7) Presenting the results, e.g., you can visualize how the MAPE or loss function changes in iterations of training.\n",
    "\n",
    "\n",
    "\n",
    "It should be possible to get a MAPE below 2%, but it may take some time and may require optimizing the parameters. \n",
    "\n",
    "The code should be prepared as a Jupyter notebook. If you need a GPU, you can use Google Colab.\n",
    "\n",
    "\n",
    "\n",
    "Questions: send an email to pawel.gora@qaif.org\n",
    "\n",
    "Submission: send the Jupyter notebook file with the code to pawel.gora@qaif.org by 22.06.2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b2005",
   "metadata": {},
   "source": [
    "1) Reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"ochota100k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b44905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    81  14   58  108  83  60   82  61   64   94  ...   28   87   73   69   25  \\\n",
      "0   81  92   16   44  95  64  110  98   95  105  ...   42    5   40  105  118   \n",
      "1   75  20   66  104  20  65   80  97    2   81  ...  119  115  118   64   68   \n",
      "2   30  42   65  108  67  81   85  32   83   48  ...  107   79   44   90    6   \n",
      "3  117  20   52   40  25  36   87  78   99   70  ...   92   21   34  102   37   \n",
      "4   47  63  110   39  39  56  116  81  111   46  ...   63   98    3  101   54   \n",
      "\n",
      "    7   77   95    5  49082  \n",
      "0  48   40   62   45  51223  \n",
      "1  46   45   43   18  51461  \n",
      "2  25   46  102   62  45119  \n",
      "3  46   11    9   66  50660  \n",
      "4  14  109   79  111  49601  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_id = \"1m5xgNXp3vv5zzH4JHfE9983cLiSR3IPp\"\n",
    "url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20885214",
   "metadata": {},
   "source": [
    "2) Splitting the dataset into a training set (first 85336 rows) and a test set (last 20000 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbfc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
